*** WARNING: This is an experimental installation of pytorch built specifically for MPI / distributed running ***
5: 2018-09-28 16:37:10,069 INFO Initializing
6: 2018-09-28 16:37:10,072 INFO Initializing
4: 2018-09-28 16:37:10,127 INFO Initializing
3: 2018-09-28 16:37:10,139 INFO Initializing
0: 2018-09-28 16:37:10,143 INFO Initializing
2: 2018-09-28 16:37:10,228 INFO Initializing
1: 2018-09-28 16:37:10,271 INFO Initializing
7: 2018-09-28 16:37:11,320 INFO Initializing
0: 2018-09-28 16:37:11,366 INFO MPI rank 0
2: 2018-09-28 16:37:11,368 INFO MPI rank 2
6: 2018-09-28 16:37:11,368 INFO MPI rank 6
3: 2018-09-28 16:37:11,368 INFO MPI rank 3
7: 2018-09-28 16:37:11,367 INFO MPI rank 7
1: 2018-09-28 16:37:11,367 INFO MPI rank 1
4: 2018-09-28 16:37:11,366 INFO MPI rank 4
5: 2018-09-28 16:37:11,366 INFO MPI rank 5
0: 2018-09-28 16:37:11,378 INFO Configuration: {'data_config': {'train_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/train.h5', 'valid_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/val.h5', 'test_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/test.h5', 'n_train': 262144, 'n_valid': 32768, 'n_test': 1024}, 'model_config': {'conv_sizes': [16, 32, 64], 'dense_sizes': [128], 'optimizer': 'Adam', 'learning_rate': 0.001, 'dropout': 0.2}, 'training_config': {'batch_size': 128, 'n_epochs': 4}, 'output_dir': '$SCRATCH/hep-cnn-pytorch'}
3: 2018-09-28 16:39:00,589 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
2: 2018-09-28 16:39:00,590 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
7: 2018-09-28 16:39:00,589 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
1: 2018-09-28 16:39:00,590 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
0: 2018-09-28 16:39:00,589 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
6: 2018-09-28 16:39:00,591 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
5: 2018-09-28 16:39:00,589 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
4: 2018-09-28 16:39:01,061 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
3: 2018-09-28 16:39:01,087 INFO Epoch 0
1: 2018-09-28 16:39:01,086 INFO Epoch 0
2: 2018-09-28 16:39:01,087 INFO Epoch 0
0: 2018-09-28 16:39:01,085 INFO Model: 
0: HEPCNNClassifier(
0:   (conv_net): Sequential(
0:     (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
0:     (1): ReLU()
0:     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
0:     (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
0:     (4): ReLU()
0:     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
0:     (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
0:     (7): ReLU()
0:     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
0:   )
0:   (dense_net): Sequential(
0:     (0): Linear(in_features=4096, out_features=128, bias=True)
0:     (1): ReLU()
0:     (2): Dropout(p=0.2)
0:     (3): Linear(in_features=128, out_features=1, bias=True)
0:     (4): Sigmoid()
0:   )
0: )
0: Parameters: 547841
0: 2018-09-28 16:39:01,085 INFO Epoch 0
6: 2018-09-28 16:39:01,095 INFO Epoch 0
7: 2018-09-28 16:39:01,093 INFO Epoch 0
4: 2018-09-28 16:39:01,092 INFO Epoch 0
5: 2018-09-28 16:39:01,093 INFO Epoch 0
0: 2018-09-28 16:39:40,363 INFO   Training loss: 0.307
7: 2018-09-28 16:39:40,364 INFO   Training loss: 0.307
5: 2018-09-28 16:39:40,364 INFO   Training loss: 0.310
2: 2018-09-28 16:39:40,365 INFO   Training loss: 0.306
6: 2018-09-28 16:39:40,365 INFO   Training loss: 0.303
3: 2018-09-28 16:39:40,365 INFO   Training loss: 0.307
4: 2018-09-28 16:39:40,363 INFO   Training loss: 0.309
1: 2018-09-28 16:39:40,364 INFO   Training loss: 0.305
0: 2018-09-28 16:39:50,912 INFO   Validation loss: 0.234 acc: 0.906
0: 2018-09-28 16:39:50,919 INFO Epoch 1
1: 2018-09-28 16:39:50,925 INFO   Validation loss: 0.234 acc: 0.906
4: 2018-09-28 16:39:50,974 INFO   Validation loss: 0.234 acc: 0.906
5: 2018-09-28 16:39:51,006 INFO   Validation loss: 0.234 acc: 0.906
5: 2018-09-28 16:39:51,975 INFO Epoch 1
1: 2018-09-28 16:39:52,400 INFO Epoch 1
4: 2018-09-28 16:39:52,441 INFO Epoch 1
3: 2018-09-28 16:39:55,915 INFO   Validation loss: 0.234 acc: 0.906
3: 2018-09-28 16:39:55,959 INFO Epoch 1
6: 2018-09-28 16:39:55,995 INFO   Validation loss: 0.234 acc: 0.906
2: 2018-09-28 16:39:56,007 INFO   Validation loss: 0.234 acc: 0.906
2: 2018-09-28 16:39:56,092 INFO Epoch 1
6: 2018-09-28 16:39:56,205 INFO Epoch 1
7: 2018-09-28 16:39:56,866 INFO   Validation loss: 0.234 acc: 0.906
7: 2018-09-28 16:39:56,966 INFO Epoch 1
6: 2018-09-28 16:40:36,003 INFO   Training loss: 0.230
7: 2018-09-28 16:40:36,001 INFO   Training loss: 0.234
5: 2018-09-28 16:40:36,001 INFO   Training loss: 0.236
2: 2018-09-28 16:40:36,003 INFO   Training loss: 0.231
0: 2018-09-28 16:40:36,001 INFO   Training loss: 0.231
3: 2018-09-28 16:40:36,003 INFO   Training loss: 0.232
1: 2018-09-28 16:40:36,002 INFO   Training loss: 0.230
4: 2018-09-28 16:40:36,000 INFO   Training loss: 0.234
0: 2018-09-28 16:40:46,531 INFO   Validation loss: 0.225 acc: 0.910
0: 2018-09-28 16:40:46,538 INFO Epoch 2
1: 2018-09-28 16:40:46,576 INFO   Validation loss: 0.225 acc: 0.910
3: 2018-09-28 16:40:46,591 INFO   Validation loss: 0.225 acc: 0.910
4: 2018-09-28 16:40:46,626 INFO   Validation loss: 0.225 acc: 0.910
6: 2018-09-28 16:40:46,671 INFO   Validation loss: 0.225 acc: 0.910
5: 2018-09-28 16:40:46,697 INFO   Validation loss: 0.225 acc: 0.910
5: 2018-09-28 16:40:48,356 INFO Epoch 2
1: 2018-09-28 16:40:49,241 INFO Epoch 2
3: 2018-09-28 16:40:49,314 INFO Epoch 2
4: 2018-09-28 16:40:49,347 INFO Epoch 2
6: 2018-09-28 16:40:49,383 INFO Epoch 2
2: 2018-09-28 16:40:51,565 INFO   Validation loss: 0.225 acc: 0.910
2: 2018-09-28 16:40:51,659 INFO Epoch 2
7: 2018-09-28 16:40:52,492 INFO   Validation loss: 0.225 acc: 0.910
7: 2018-09-28 16:40:52,636 INFO Epoch 2
0: 2018-09-28 16:41:33,113 INFO   Training loss: 0.228
3: 2018-09-28 16:41:33,115 INFO   Training loss: 0.229
7: 2018-09-28 16:41:33,113 INFO   Training loss: 0.230
5: 2018-09-28 16:41:33,113 INFO   Training loss: 0.232
6: 2018-09-28 16:41:33,115 INFO   Training loss: 0.225
1: 2018-09-28 16:41:33,114 INFO   Training loss: 0.225
2: 2018-09-28 16:41:33,116 INFO   Training loss: 0.227
4: 2018-09-28 16:41:33,113 INFO   Training loss: 0.230
1: 2018-09-28 16:41:43,660 INFO   Validation loss: 0.222 acc: 0.910
1: 2018-09-28 16:41:43,667 INFO Epoch 3
3: 2018-09-28 16:41:43,670 INFO   Validation loss: 0.222 acc: 0.910
3: 2018-09-28 16:41:43,734 INFO Epoch 3
4: 2018-09-28 16:41:43,753 INFO   Validation loss: 0.222 acc: 0.910
5: 2018-09-28 16:41:43,788 INFO   Validation loss: 0.222 acc: 0.910
6: 2018-09-28 16:41:43,805 INFO   Validation loss: 0.222 acc: 0.910
5: 2018-09-28 16:41:44,652 INFO Epoch 3
4: 2018-09-28 16:41:45,095 INFO Epoch 3
6: 2018-09-28 16:41:45,131 INFO Epoch 3
2: 2018-09-28 16:41:48,671 INFO   Validation loss: 0.222 acc: 0.910
2: 2018-09-28 16:41:48,709 INFO Epoch 3
0: 2018-09-28 16:41:48,832 INFO   Validation loss: 0.222 acc: 0.910
0: 2018-09-28 16:41:48,949 INFO Epoch 3
7: 2018-09-28 16:41:49,692 INFO   Validation loss: 0.222 acc: 0.910
7: 2018-09-28 16:41:49,818 INFO Epoch 3
0: 2018-09-28 16:42:30,642 INFO   Training loss: 0.224
3: 2018-09-28 16:42:30,644 INFO   Training loss: 0.225
5: 2018-09-28 16:42:30,642 INFO   Training loss: 0.229
2: 2018-09-28 16:42:30,644 INFO   Training loss: 0.224
6: 2018-09-28 16:42:30,644 INFO   Training loss: 0.223
7: 2018-09-28 16:42:30,642 INFO   Training loss: 0.228
1: 2018-09-28 16:42:30,643 INFO   Training loss: 0.222
4: 2018-09-28 16:42:30,642 INFO   Training loss: 0.228
3: 2018-09-28 16:42:41,189 INFO   Validation loss: 0.223 acc: 0.910
3: 2018-09-28 16:42:41,198 INFO Finished training
3: 2018-09-28 16:42:41,198 INFO Train samples 32768 time 42.508s rate 770.866 samples/s
3: 2018-09-28 16:42:41,198 INFO Valid rate: 2774.78 samples/s
3: 2018-09-28 16:42:41,198 INFO All done!
6: 2018-09-28 16:42:41,202 INFO   Validation loss: 0.223 acc: 0.910
1: 2018-09-28 16:42:41,213 INFO   Validation loss: 0.223 acc: 0.910
4: 2018-09-28 16:42:41,268 INFO   Validation loss: 0.223 acc: 0.910
5: 2018-09-28 16:42:41,316 INFO   Validation loss: 0.223 acc: 0.910
5: 2018-09-28 16:42:42,692 INFO Finished training
5: 2018-09-28 16:42:42,692 INFO Train samples 32768 time 43.5106s rate 753.104 samples/s
5: 2018-09-28 16:42:42,692 INFO Valid rate: 3070.65 samples/s
5: 2018-09-28 16:42:42,692 INFO All done!
6: 2018-09-28 16:42:43,190 INFO Finished training
6: 2018-09-28 16:42:43,190 INFO Train samples 32768 time 42.0779s rate 778.746 samples/s
6: 2018-09-28 16:42:43,190 INFO Valid rate: 2756.85 samples/s
6: 2018-09-28 16:42:43,190 INFO All done!
1: 2018-09-28 16:42:43,230 INFO Finished training
1: 2018-09-28 16:42:43,230 INFO Train samples 32768 time 43.4324s rate 754.459 samples/s
1: 2018-09-28 16:42:43,230 INFO Valid rate: 3102.36 samples/s
1: 2018-09-28 16:42:43,231 INFO All done!
4: 2018-09-28 16:42:43,255 INFO Finished training
4: 2018-09-28 16:42:43,255 INFO Train samples 32768 time 43.0354s rate 761.42 samples/s
4: 2018-09-28 16:42:43,255 INFO Valid rate: 3083.92 samples/s
4: 2018-09-28 16:42:43,255 INFO All done!
2: 2018-09-28 16:42:46,261 INFO   Validation loss: 0.223 acc: 0.910
2: 2018-09-28 16:42:46,314 INFO Finished training
2: 2018-09-28 16:42:46,315 INFO Train samples 32768 time 40.6448s rate 806.204 samples/s
2: 2018-09-28 16:42:46,315 INFO Valid rate: 2101.38 samples/s
2: 2018-09-28 16:42:46,315 INFO All done!
0: 2018-09-28 16:42:46,353 INFO   Validation loss: 0.223 acc: 0.910
0: 2018-09-28 16:42:46,419 INFO Saving summaries to /global/cscratch1/sd/sfarrell/hep-cnn-pytorch/summaries.npz
0: 2018-09-28 16:42:46,431 INFO Finished training
0: 2018-09-28 16:42:46,431 INFO Train samples 32768 time 43.1567s rate 759.279 samples/s
0: 2018-09-28 16:42:46,431 INFO Valid rate: 2496.23 samples/s
0: 2018-09-28 16:42:46,431 INFO All done!
7: 2018-09-28 16:42:47,265 INFO   Validation loss: 0.223 acc: 0.910
7: 2018-09-28 16:42:47,320 INFO Finished training
7: 2018-09-28 16:42:47,320 INFO Train samples 32768 time 39.9014s rate 821.224 samples/s
7: 2018-09-28 16:42:47,321 INFO Valid rate: 1980.14 samples/s
7: 2018-09-28 16:42:47,321 INFO All done!
