*** WARNING: This is an experimental installation of pytorch built specifically for MPI / distributed running ***
 3: 2018-09-29 12:12:55,529 INFO Initializing
 2: 2018-09-29 12:12:55,529 INFO Initializing
 4: 2018-09-29 12:12:55,529 INFO Initializing
26: 2018-09-29 12:12:55,532 INFO Initializing
18: 2018-09-29 12:12:55,529 INFO Initializing
15: 2018-09-29 12:12:55,530 INFO Initializing
 8: 2018-09-29 12:12:55,529 INFO Initializing
27: 2018-09-29 12:12:55,530 INFO Initializing
 5: 2018-09-29 12:12:55,532 INFO Initializing
20: 2018-09-29 12:12:55,530 INFO Initializing
 6: 2018-09-29 12:12:55,530 INFO Initializing
 7: 2018-09-29 12:12:55,532 INFO Initializing
13: 2018-09-29 12:12:55,531 INFO Initializing
11: 2018-09-29 12:12:55,532 INFO Initializing
19: 2018-09-29 12:12:55,531 INFO Initializing
10: 2018-09-29 12:12:55,531 INFO Initializing
12: 2018-09-29 12:12:55,530 INFO Initializing
14: 2018-09-29 12:12:55,531 INFO Initializing
17: 2018-09-29 12:12:55,530 INFO Initializing
21: 2018-09-29 12:12:55,533 INFO Initializing
 9: 2018-09-29 12:12:55,530 INFO Initializing
22: 2018-09-29 12:12:55,531 INFO Initializing
28: 2018-09-29 12:12:55,529 INFO Initializing
23: 2018-09-29 12:12:55,534 INFO Initializing
30: 2018-09-29 12:12:55,531 INFO Initializing
 1: 2018-09-29 12:12:55,555 INFO Initializing
24: 2018-09-29 12:12:55,552 INFO Initializing
25: 2018-09-29 12:12:55,531 INFO Initializing
29: 2018-09-29 12:12:55,531 INFO Initializing
 0: 2018-09-29 12:12:55,534 INFO Initializing
16: 2018-09-29 12:12:55,566 INFO Initializing
31: 2018-09-29 12:12:55,571 INFO Initializing
 6: 2018-09-29 12:12:55,616 INFO MPI rank 6
22: 2018-09-29 12:12:55,618 INFO MPI rank 22
30: 2018-09-29 12:12:55,618 INFO MPI rank 30
26: 2018-09-29 12:12:55,620 INFO MPI rank 26
20: 2018-09-29 12:12:55,617 INFO MPI rank 20
16: 2018-09-29 12:12:55,618 INFO MPI rank 16
18: 2018-09-29 12:12:55,617 INFO MPI rank 18
10: 2018-09-29 12:12:55,618 INFO MPI rank 10
12: 2018-09-29 12:12:55,617 INFO MPI rank 12
14: 2018-09-29 12:12:55,618 INFO MPI rank 14
28: 2018-09-29 12:12:55,616 INFO MPI rank 28
 2: 2018-09-29 12:12:55,617 INFO MPI rank 2
 4: 2018-09-29 12:12:55,617 INFO MPI rank 4
 0: 2018-09-29 12:12:55,618 INFO MPI rank 0
 5: 2018-09-29 12:12:55,618 INFO MPI rank 5
 7: 2018-09-29 12:12:55,618 INFO MPI rank 7
13: 2018-09-29 12:12:55,618 INFO MPI rank 13
11: 2018-09-29 12:12:55,618 INFO MPI rank 11
19: 2018-09-29 12:12:55,618 INFO MPI rank 19
17: 2018-09-29 12:12:55,617 INFO MPI rank 17
15: 2018-09-29 12:12:55,618 INFO MPI rank 15
21: 2018-09-29 12:12:55,618 INFO MPI rank 21
 9: 2018-09-29 12:12:55,617 INFO MPI rank 9
 8: 2018-09-29 12:12:55,617 INFO MPI rank 8
23: 2018-09-29 12:12:55,618 INFO MPI rank 23
 1: 2018-09-29 12:12:55,618 INFO MPI rank 1
31: 2018-09-29 12:12:55,619 INFO MPI rank 31
24: 2018-09-29 12:12:55,615 INFO MPI rank 24
 3: 2018-09-29 12:12:55,617 INFO MPI rank 3
25: 2018-09-29 12:12:55,618 INFO MPI rank 25
27: 2018-09-29 12:12:55,618 INFO MPI rank 27
29: 2018-09-29 12:12:55,618 INFO MPI rank 29
 0: 2018-09-29 12:12:55,633 INFO Configuration: {'data_config': {'train_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/train.h5', 'valid_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/val.h5', 'test_file': '/global/cscratch1/sd/sfarrell/atlas-rpv-images/test.h5', 'n_train': 262144, 'n_valid': 32768, 'n_test': 1024}, 'model_config': {'conv_sizes': [16, 32, 64], 'dense_sizes': [128], 'optimizer': 'Adam', 'learning_rate': 0.001, 'dropout': 0.2}, 'training_config': {'batch_size': 128, 'n_epochs': 4}, 'output_dir': '$SCRATCH/hep-cnn-pytorch'}
12: 2018-09-29 12:14:36,655 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 8: 2018-09-29 12:14:36,656 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 9: 2018-09-29 12:14:36,656 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
31: 2018-09-29 12:14:36,658 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
21: 2018-09-29 12:14:36,665 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 6: 2018-09-29 12:14:36,665 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 2: 2018-09-29 12:14:36,666 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
28: 2018-09-29 12:14:36,665 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 0: 2018-09-29 12:14:36,667 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
18: 2018-09-29 12:14:36,667 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 4: 2018-09-29 12:14:36,667 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
15: 2018-09-29 12:14:36,668 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
13: 2018-09-29 12:14:36,668 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
23: 2018-09-29 12:14:36,668 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
17: 2018-09-29 12:14:36,668 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 5: 2018-09-29 12:14:36,669 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
25: 2018-09-29 12:14:36,670 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
20: 2018-09-29 12:14:36,668 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
11: 2018-09-29 12:14:36,670 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
30: 2018-09-29 12:14:36,673 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
26: 2018-09-29 12:14:36,702 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 1: 2018-09-29 12:14:36,733 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
29: 2018-09-29 12:14:36,770 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
27: 2018-09-29 12:14:36,784 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 7: 2018-09-29 12:14:36,811 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
10: 2018-09-29 12:14:36,821 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
 3: 2018-09-29 12:14:36,839 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
16: 2018-09-29 12:14:36,946 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
24: 2018-09-29 12:14:37,003 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
14: 2018-09-29 12:14:37,033 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
19: 2018-09-29 12:14:37,051 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
13: 2018-09-29 12:14:37,074 INFO Epoch 0
12: 2018-09-29 12:14:37,074 INFO Epoch 0
10: 2018-09-29 12:14:37,075 INFO Epoch 0
14: 2018-09-29 12:14:37,075 INFO Epoch 0
15: 2018-09-29 12:14:37,074 INFO Epoch 0
 1: 2018-09-29 12:14:37,074 INFO Epoch 0
 3: 2018-09-29 12:14:37,074 INFO Epoch 0
 2: 2018-09-29 12:14:37,074 INFO Epoch 0
11: 2018-09-29 12:14:37,075 INFO Epoch 0
 9: 2018-09-29 12:14:37,073 INFO Epoch 0
 8: 2018-09-29 12:14:37,073 INFO Epoch 0
 0: 2018-09-29 12:14:37,075 INFO Model: 
 0: HEPCNNClassifier(
 0:   (conv_net): Sequential(
 0:     (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
 0:     (1): ReLU()
 0:     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
 0:     (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
 0:     (4): ReLU()
 0:     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
 0:     (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
 0:     (7): ReLU()
 0:     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
 0:   )
 0:   (dense_net): Sequential(
 0:     (0): Linear(in_features=4096, out_features=128, bias=True)
 0:     (1): ReLU()
 0:     (2): Dropout(p=0.2)
 0:     (3): Linear(in_features=128, out_features=1, bias=True)
 0:     (4): Sigmoid()
 0:   )
 0: )
 0: Parameters: 547841
 0: 2018-09-29 12:14:37,075 INFO Epoch 0
 4: 2018-09-29 12:14:37,081 INFO Epoch 0
 5: 2018-09-29 12:14:37,083 INFO Epoch 0
 6: 2018-09-29 12:14:37,081 INFO Epoch 0
 7: 2018-09-29 12:14:37,083 INFO Epoch 0
22: 2018-09-29 12:14:37,098 INFO Loaded data with shape: torch.Size([262144, 1, 64, 64])
28: 2018-09-29 12:14:37,111 INFO Epoch 0
30: 2018-09-29 12:14:37,113 INFO Epoch 0
24: 2018-09-29 12:14:37,110 INFO Epoch 0
25: 2018-09-29 12:14:37,113 INFO Epoch 0
27: 2018-09-29 12:14:37,113 INFO Epoch 0
26: 2018-09-29 12:14:37,115 INFO Epoch 0
29: 2018-09-29 12:14:37,113 INFO Epoch 0
16: 2018-09-29 12:14:37,113 INFO Epoch 0
17: 2018-09-29 12:14:37,113 INFO Epoch 0
31: 2018-09-29 12:14:37,114 INFO Epoch 0
19: 2018-09-29 12:14:37,113 INFO Epoch 0
18: 2018-09-29 12:14:37,112 INFO Epoch 0
20: 2018-09-29 12:14:37,120 INFO Epoch 0
21: 2018-09-29 12:14:37,120 INFO Epoch 0
22: 2018-09-29 12:14:37,121 INFO Epoch 0
23: 2018-09-29 12:14:37,121 INFO Epoch 0
19: 2018-09-29 12:14:48,173 INFO   Training loss: 11.873
18: 2018-09-29 12:14:48,172 INFO   Training loss: 11.523
10: 2018-09-29 12:14:48,173 INFO   Training loss: 11.776
 3: 2018-09-29 12:14:48,173 INFO   Training loss: 11.803
26: 2018-09-29 12:14:48,175 INFO   Training loss: 11.846
 4: 2018-09-29 12:14:48,172 INFO   Training loss: 11.469
 6: 2018-09-29 12:14:48,172 INFO   Training loss: 11.816
13: 2018-09-29 12:14:48,173 INFO   Training loss: 11.742
11: 2018-09-29 12:14:48,174 INFO   Training loss: 11.428
12: 2018-09-29 12:14:48,172 INFO   Training loss: 11.428
14: 2018-09-29 12:14:48,173 INFO   Training loss: 11.364
15: 2018-09-29 12:14:48,173 INFO   Training loss: 11.705
 8: 2018-09-29 12:14:48,172 INFO   Training loss: 11.617
22: 2018-09-29 12:14:48,173 INFO   Training loss: 11.469
30: 2018-09-29 12:14:48,173 INFO   Training loss: 11.624
 1: 2018-09-29 12:14:48,173 INFO   Training loss: 11.475
31: 2018-09-29 12:14:48,174 INFO   Training loss: 11.759
27: 2018-09-29 12:14:48,173 INFO   Training loss: 11.840
 5: 2018-09-29 12:14:48,173 INFO   Training loss: 11.705
20: 2018-09-29 12:14:48,172 INFO   Training loss: 11.502
 7: 2018-09-29 12:14:48,174 INFO   Training loss: 11.681
16: 2018-09-29 12:14:48,174 INFO   Training loss: 11.816
17: 2018-09-29 12:14:48,173 INFO   Training loss: 11.641
21: 2018-09-29 12:14:48,173 INFO   Training loss: 11.701
 9: 2018-09-29 12:14:48,172 INFO   Training loss: 11.735
28: 2018-09-29 12:14:48,172 INFO   Training loss: 11.496
23: 2018-09-29 12:14:48,173 INFO   Training loss: 11.705
24: 2018-09-29 12:14:48,171 INFO   Training loss: 11.341
 2: 2018-09-29 12:14:48,173 INFO   Training loss: 11.513
25: 2018-09-29 12:14:48,174 INFO   Training loss: 11.799
29: 2018-09-29 12:14:48,173 INFO   Training loss: 11.644
 0: 2018-09-29 12:14:48,173 INFO   Training loss: 11.523
 7: 2018-09-29 12:14:58,613 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:14:58,622 INFO   Validation loss: 11.783 acc: 0.574
10: 2018-09-29 12:14:58,642 INFO   Validation loss: 11.783 acc: 0.574
30: 2018-09-29 12:14:58,650 INFO   Validation loss: 11.783 acc: 0.574
24: 2018-09-29 12:14:58,648 INFO   Validation loss: 11.783 acc: 0.574
27: 2018-09-29 12:14:58,662 INFO   Validation loss: 11.783 acc: 0.574
17: 2018-09-29 12:14:58,663 INFO   Validation loss: 11.783 acc: 0.574
 9: 2018-09-29 12:14:58,671 INFO   Validation loss: 11.783 acc: 0.574
 5: 2018-09-29 12:14:58,676 INFO   Validation loss: 11.783 acc: 0.574
 4: 2018-09-29 12:14:58,691 INFO   Validation loss: 11.783 acc: 0.574
15: 2018-09-29 12:14:58,699 INFO   Validation loss: 11.783 acc: 0.574
 1: 2018-09-29 12:14:58,701 INFO   Validation loss: 11.783 acc: 0.574
 6: 2018-09-29 12:14:58,706 INFO   Validation loss: 11.783 acc: 0.574
 2: 2018-09-29 12:14:58,715 INFO   Validation loss: 11.783 acc: 0.574
29: 2018-09-29 12:14:58,734 INFO   Validation loss: 11.783 acc: 0.574
 8: 2018-09-29 12:14:58,741 INFO   Validation loss: 11.783 acc: 0.574
31: 2018-09-29 12:14:58,758 INFO   Validation loss: 11.783 acc: 0.574
 0: 2018-09-29 12:14:58,773 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:14:58,773 INFO   Validation loss: 11.783 acc: 0.574
26: 2018-09-29 12:14:58,783 INFO   Validation loss: 11.783 acc: 0.574
11: 2018-09-29 12:14:58,804 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:14:59,270 INFO Epoch 1
12: 2018-09-29 12:15:02,773 INFO Epoch 1
20: 2018-09-29 12:15:03,656 INFO   Validation loss: 11.783 acc: 0.574
22: 2018-09-29 12:15:03,696 INFO   Validation loss: 11.783 acc: 0.574
18: 2018-09-29 12:15:03,715 INFO   Validation loss: 11.783 acc: 0.574
28: 2018-09-29 12:15:03,729 INFO   Validation loss: 11.783 acc: 0.574
16: 2018-09-29 12:15:03,738 INFO   Validation loss: 11.783 acc: 0.574
 3: 2018-09-29 12:15:03,749 INFO   Validation loss: 11.783 acc: 0.574
23: 2018-09-29 12:15:03,772 INFO   Validation loss: 11.783 acc: 0.574
13: 2018-09-29 12:15:04,658 INFO   Validation loss: 11.783 acc: 0.574
21: 2018-09-29 12:15:04,659 INFO   Validation loss: 11.783 acc: 0.574
19: 2018-09-29 12:15:04,661 INFO   Validation loss: 11.783 acc: 0.574
14: 2018-09-29 12:15:04,742 INFO   Validation loss: 11.783 acc: 0.574
 7: 2018-09-29 12:15:06,830 INFO Epoch 1
10: 2018-09-29 12:15:07,397 INFO Epoch 1
27: 2018-09-29 12:15:07,462 INFO Epoch 1
30: 2018-09-29 12:15:07,480 INFO Epoch 1
24: 2018-09-29 12:15:07,510 INFO Epoch 1
 9: 2018-09-29 12:15:07,547 INFO Epoch 1
17: 2018-09-29 12:15:07,590 INFO Epoch 1
 4: 2018-09-29 12:15:07,613 INFO Epoch 1
 5: 2018-09-29 12:15:07,677 INFO Epoch 1
 1: 2018-09-29 12:15:07,681 INFO Epoch 1
15: 2018-09-29 12:15:07,750 INFO Epoch 1
 6: 2018-09-29 12:15:07,771 INFO Epoch 1
 2: 2018-09-29 12:15:07,788 INFO Epoch 1
29: 2018-09-29 12:15:07,870 INFO Epoch 1
 0: 2018-09-29 12:15:07,888 INFO Epoch 1
31: 2018-09-29 12:15:07,916 INFO Epoch 1
26: 2018-09-29 12:15:07,932 INFO Epoch 1
 8: 2018-09-29 12:15:07,946 INFO Epoch 1
11: 2018-09-29 12:15:08,052 INFO Epoch 1
22: 2018-09-29 12:15:08,450 INFO Epoch 1
21: 2018-09-29 12:15:08,778 INFO Epoch 1
23: 2018-09-29 12:15:08,803 INFO Epoch 1
19: 2018-09-29 12:15:09,088 INFO Epoch 1
28: 2018-09-29 12:15:09,815 INFO Epoch 1
20: 2018-09-29 12:15:09,857 INFO Epoch 1
 3: 2018-09-29 12:15:09,881 INFO Epoch 1
18: 2018-09-29 12:15:09,908 INFO Epoch 1
16: 2018-09-29 12:15:09,958 INFO Epoch 1
13: 2018-09-29 12:15:10,034 INFO Epoch 1
14: 2018-09-29 12:15:10,060 INFO Epoch 1
28: 2018-09-29 12:15:20,879 INFO   Training loss: 11.711
 1: 2018-09-29 12:15:20,880 INFO   Training loss: 11.640
 0: 2018-09-29 12:15:20,880 INFO   Training loss: 11.721
20: 2018-09-29 12:15:20,879 INFO   Training loss: 11.667
11: 2018-09-29 12:15:20,881 INFO   Training loss: 11.637
18: 2018-09-29 12:15:20,879 INFO   Training loss: 11.670
14: 2018-09-29 12:15:20,880 INFO   Training loss: 11.546
17: 2018-09-29 12:15:20,880 INFO   Training loss: 11.819
15: 2018-09-29 12:15:20,880 INFO   Training loss: 11.886
21: 2018-09-29 12:15:20,880 INFO   Training loss: 11.873
31: 2018-09-29 12:15:20,881 INFO   Training loss: 11.947
25: 2018-09-29 12:15:20,881 INFO   Training loss: 11.944
27: 2018-09-29 12:15:20,880 INFO   Training loss: 12.004
 5: 2018-09-29 12:15:20,881 INFO   Training loss: 11.869
 6: 2018-09-29 12:15:20,879 INFO   Training loss: 12.008
 7: 2018-09-29 12:15:20,881 INFO   Training loss: 11.846
13: 2018-09-29 12:15:20,880 INFO   Training loss: 11.930
19: 2018-09-29 12:15:20,880 INFO   Training loss: 12.065
16: 2018-09-29 12:15:20,881 INFO   Training loss: 12.001
10: 2018-09-29 12:15:20,881 INFO   Training loss: 11.937
12: 2018-09-29 12:15:20,880 INFO   Training loss: 11.623
 9: 2018-09-29 12:15:20,879 INFO   Training loss: 11.886
 8: 2018-09-29 12:15:20,879 INFO   Training loss: 11.785
22: 2018-09-29 12:15:20,880 INFO   Training loss: 11.599
23: 2018-09-29 12:15:20,880 INFO   Training loss: 11.849
30: 2018-09-29 12:15:20,880 INFO   Training loss: 11.785
24: 2018-09-29 12:15:20,878 INFO   Training loss: 11.519
 3: 2018-09-29 12:15:20,880 INFO   Training loss: 11.967
 2: 2018-09-29 12:15:20,880 INFO   Training loss: 11.670
26: 2018-09-29 12:15:20,882 INFO   Training loss: 12.028
29: 2018-09-29 12:15:20,880 INFO   Training loss: 11.832
 4: 2018-09-29 12:15:20,880 INFO   Training loss: 11.640
22: 2018-09-29 12:15:31,304 INFO   Validation loss: 11.783 acc: 0.574
22: 2018-09-29 12:15:31,311 INFO Epoch 2
24: 2018-09-29 12:15:31,317 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:15:31,364 INFO   Validation loss: 11.783 acc: 0.574
 5: 2018-09-29 12:15:31,383 INFO   Validation loss: 11.783 acc: 0.574
23: 2018-09-29 12:15:31,383 INFO   Validation loss: 11.783 acc: 0.574
10: 2018-09-29 12:15:31,387 INFO   Validation loss: 11.783 acc: 0.574
 9: 2018-09-29 12:15:31,394 INFO   Validation loss: 11.783 acc: 0.574
29: 2018-09-29 12:15:31,399 INFO   Validation loss: 11.783 acc: 0.574
15: 2018-09-29 12:15:31,409 INFO   Validation loss: 11.783 acc: 0.574
26: 2018-09-29 12:15:31,413 INFO   Validation loss: 11.783 acc: 0.574
 2: 2018-09-29 12:15:31,422 INFO   Validation loss: 11.783 acc: 0.574
27: 2018-09-29 12:15:31,426 INFO   Validation loss: 11.783 acc: 0.574
 1: 2018-09-29 12:15:31,438 INFO   Validation loss: 11.783 acc: 0.574
 7: 2018-09-29 12:15:31,452 INFO   Validation loss: 11.783 acc: 0.574
 8: 2018-09-29 12:15:31,456 INFO   Validation loss: 11.783 acc: 0.574
31: 2018-09-29 12:15:31,461 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:15:31,494 INFO   Validation loss: 11.783 acc: 0.574
17: 2018-09-29 12:15:31,499 INFO   Validation loss: 11.783 acc: 0.574
 6: 2018-09-29 12:15:31,508 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:15:32,334 INFO Epoch 2
30: 2018-09-29 12:15:36,419 INFO   Validation loss: 11.783 acc: 0.574
 4: 2018-09-29 12:15:36,424 INFO   Validation loss: 11.783 acc: 0.574
 0: 2018-09-29 12:15:36,434 INFO   Validation loss: 11.783 acc: 0.574
 3: 2018-09-29 12:15:36,479 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:15:36,490 INFO Epoch 2
28: 2018-09-29 12:15:36,492 INFO   Validation loss: 11.783 acc: 0.574
16: 2018-09-29 12:15:36,502 INFO   Validation loss: 11.783 acc: 0.574
11: 2018-09-29 12:15:36,533 INFO   Validation loss: 11.783 acc: 0.574
18: 2018-09-29 12:15:37,406 INFO   Validation loss: 11.783 acc: 0.574
19: 2018-09-29 12:15:37,416 INFO   Validation loss: 11.783 acc: 0.574
21: 2018-09-29 12:15:37,419 INFO   Validation loss: 11.783 acc: 0.574
20: 2018-09-29 12:15:37,420 INFO   Validation loss: 11.783 acc: 0.574
13: 2018-09-29 12:15:37,422 INFO   Validation loss: 11.783 acc: 0.574
14: 2018-09-29 12:15:37,554 INFO   Validation loss: 11.783 acc: 0.574
24: 2018-09-29 12:15:38,706 INFO Epoch 2
23: 2018-09-29 12:15:39,167 INFO Epoch 2
 5: 2018-09-29 12:15:39,244 INFO Epoch 2
10: 2018-09-29 12:15:39,268 INFO Epoch 2
 9: 2018-09-29 12:15:39,494 INFO Epoch 2
 1: 2018-09-29 12:15:39,680 INFO Epoch 2
15: 2018-09-29 12:15:39,708 INFO Epoch 2
26: 2018-09-29 12:15:39,758 INFO Epoch 2
29: 2018-09-29 12:15:39,822 INFO Epoch 2
 2: 2018-09-29 12:15:39,848 INFO Epoch 2
 8: 2018-09-29 12:15:39,882 INFO Epoch 2
27: 2018-09-29 12:15:39,911 INFO Epoch 2
31: 2018-09-29 12:15:39,937 INFO Epoch 2
17: 2018-09-29 12:15:39,968 INFO Epoch 2
 7: 2018-09-29 12:15:39,991 INFO Epoch 2
 6: 2018-09-29 12:15:40,024 INFO Epoch 2
21: 2018-09-29 12:15:40,990 INFO Epoch 2
 0: 2018-09-29 12:15:41,639 INFO Epoch 2
 4: 2018-09-29 12:15:41,701 INFO Epoch 2
19: 2018-09-29 12:15:41,974 INFO Epoch 2
30: 2018-09-29 12:15:42,335 INFO Epoch 2
 3: 2018-09-29 12:15:42,403 INFO Epoch 2
28: 2018-09-29 12:15:42,424 INFO Epoch 2
16: 2018-09-29 12:15:42,512 INFO Epoch 2
11: 2018-09-29 12:15:42,555 INFO Epoch 2
18: 2018-09-29 12:15:42,796 INFO Epoch 2
13: 2018-09-29 12:15:42,828 INFO Epoch 2
20: 2018-09-29 12:15:42,861 INFO Epoch 2
14: 2018-09-29 12:15:42,887 INFO Epoch 2
10: 2018-09-29 12:15:53,690 INFO   Training loss: 11.937
17: 2018-09-29 12:15:53,690 INFO   Training loss: 11.819
15: 2018-09-29 12:15:53,690 INFO   Training loss: 11.886
 1: 2018-09-29 12:15:53,690 INFO   Training loss: 11.640
31: 2018-09-29 12:15:53,691 INFO   Training loss: 11.947
24: 2018-09-29 12:15:53,687 INFO   Training loss: 11.519
29: 2018-09-29 12:15:53,690 INFO   Training loss: 11.832
 5: 2018-09-29 12:15:53,691 INFO   Training loss: 11.869
 7: 2018-09-29 12:15:53,691 INFO   Training loss: 11.846
13: 2018-09-29 12:15:53,690 INFO   Training loss: 11.930
11: 2018-09-29 12:15:53,691 INFO   Training loss: 11.637
19: 2018-09-29 12:15:53,690 INFO   Training loss: 12.065
16: 2018-09-29 12:15:53,691 INFO   Training loss: 12.001
18: 2018-09-29 12:15:53,689 INFO   Training loss: 11.670
12: 2018-09-29 12:15:53,689 INFO   Training loss: 11.623
14: 2018-09-29 12:15:53,690 INFO   Training loss: 11.546
21: 2018-09-29 12:15:53,690 INFO   Training loss: 11.873
 8: 2018-09-29 12:15:53,689 INFO   Training loss: 11.785
22: 2018-09-29 12:15:53,690 INFO   Training loss: 11.599
30: 2018-09-29 12:15:53,690 INFO   Training loss: 11.785
27: 2018-09-29 12:15:53,690 INFO   Training loss: 12.004
20: 2018-09-29 12:15:53,689 INFO   Training loss: 11.667
 6: 2018-09-29 12:15:53,689 INFO   Training loss: 12.008
 9: 2018-09-29 12:15:53,689 INFO   Training loss: 11.886
28: 2018-09-29 12:15:53,689 INFO   Training loss: 11.711
23: 2018-09-29 12:15:53,690 INFO   Training loss: 11.849
 3: 2018-09-29 12:15:53,690 INFO   Training loss: 11.967
 2: 2018-09-29 12:15:53,690 INFO   Training loss: 11.670
25: 2018-09-29 12:15:53,691 INFO   Training loss: 11.944
26: 2018-09-29 12:15:53,692 INFO   Training loss: 12.028
 4: 2018-09-29 12:15:53,690 INFO   Training loss: 11.640
 0: 2018-09-29 12:15:53,690 INFO   Training loss: 11.721
24: 2018-09-29 12:16:04,166 INFO   Validation loss: 11.783 acc: 0.574
24: 2018-09-29 12:16:04,173 INFO Epoch 3
15: 2018-09-29 12:16:04,183 INFO   Validation loss: 11.783 acc: 0.574
 5: 2018-09-29 12:16:04,189 INFO   Validation loss: 11.783 acc: 0.574
10: 2018-09-29 12:16:04,192 INFO   Validation loss: 11.783 acc: 0.574
 1: 2018-09-29 12:16:04,213 INFO   Validation loss: 11.783 acc: 0.574
 7: 2018-09-29 12:16:04,222 INFO   Validation loss: 11.783 acc: 0.574
 6: 2018-09-29 12:16:04,226 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:16:04,232 INFO   Validation loss: 11.783 acc: 0.574
 2: 2018-09-29 12:16:04,239 INFO   Validation loss: 11.783 acc: 0.574
26: 2018-09-29 12:16:04,254 INFO   Validation loss: 11.783 acc: 0.574
30: 2018-09-29 12:16:04,254 INFO   Validation loss: 11.783 acc: 0.574
29: 2018-09-29 12:16:04,263 INFO   Validation loss: 11.783 acc: 0.574
 9: 2018-09-29 12:16:04,264 INFO   Validation loss: 11.783 acc: 0.574
27: 2018-09-29 12:16:04,271 INFO   Validation loss: 11.783 acc: 0.574
 8: 2018-09-29 12:16:04,275 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:16:04,287 INFO   Validation loss: 11.783 acc: 0.574
17: 2018-09-29 12:16:04,301 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:16:08,321 INFO Epoch 3
 1: 2018-09-29 12:16:09,156 INFO Epoch 3
22: 2018-09-29 12:16:09,252 INFO   Validation loss: 11.783 acc: 0.574
 4: 2018-09-29 12:16:09,275 INFO   Validation loss: 11.783 acc: 0.574
28: 2018-09-29 12:16:09,287 INFO   Validation loss: 11.783 acc: 0.574
 3: 2018-09-29 12:16:09,291 INFO   Validation loss: 11.783 acc: 0.574
31: 2018-09-29 12:16:09,292 INFO   Validation loss: 11.783 acc: 0.574
11: 2018-09-29 12:16:09,302 INFO   Validation loss: 11.783 acc: 0.574
23: 2018-09-29 12:16:09,351 INFO   Validation loss: 11.783 acc: 0.574
16: 2018-09-29 12:16:09,359 INFO   Validation loss: 11.783 acc: 0.574
18: 2018-09-29 12:16:10,182 INFO   Validation loss: 11.783 acc: 0.574
20: 2018-09-29 12:16:10,240 INFO   Validation loss: 11.783 acc: 0.574
 0: 2018-09-29 12:16:10,258 INFO   Validation loss: 11.783 acc: 0.574
19: 2018-09-29 12:16:10,258 INFO   Validation loss: 11.783 acc: 0.574
21: 2018-09-29 12:16:10,274 INFO   Validation loss: 11.783 acc: 0.574
14: 2018-09-29 12:16:10,326 INFO   Validation loss: 11.783 acc: 0.574
13: 2018-09-29 12:16:10,360 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:16:10,553 INFO Epoch 3
15: 2018-09-29 12:16:10,593 INFO Epoch 3
 5: 2018-09-29 12:16:10,620 INFO Epoch 3
 7: 2018-09-29 12:16:10,652 INFO Epoch 3
10: 2018-09-29 12:16:10,683 INFO Epoch 3
 6: 2018-09-29 12:16:10,720 INFO Epoch 3
29: 2018-09-29 12:16:10,752 INFO Epoch 3
26: 2018-09-29 12:16:10,783 INFO Epoch 3
 2: 2018-09-29 12:16:10,806 INFO Epoch 3
27: 2018-09-29 12:16:10,823 INFO Epoch 3
30: 2018-09-29 12:16:10,839 INFO Epoch 3
 9: 2018-09-29 12:16:10,873 INFO Epoch 3
 8: 2018-09-29 12:16:10,929 INFO Epoch 3
17: 2018-09-29 12:16:11,173 INFO Epoch 3
22: 2018-09-29 12:16:13,163 INFO Epoch 3
21: 2018-09-29 12:16:13,994 INFO Epoch 3
31: 2018-09-29 12:16:14,187 INFO Epoch 3
23: 2018-09-29 12:16:14,237 INFO Epoch 3
 4: 2018-09-29 12:16:14,806 INFO Epoch 3
28: 2018-09-29 12:16:16,403 INFO Epoch 3
 3: 2018-09-29 12:16:16,503 INFO Epoch 3
11: 2018-09-29 12:16:16,613 INFO Epoch 3
16: 2018-09-29 12:16:16,644 INFO Epoch 3
19: 2018-09-29 12:16:16,767 INFO Epoch 3
 0: 2018-09-29 12:16:16,799 INFO Epoch 3
18: 2018-09-29 12:16:16,845 INFO Epoch 3
20: 2018-09-29 12:16:16,870 INFO Epoch 3
14: 2018-09-29 12:16:17,036 INFO Epoch 3
13: 2018-09-29 12:16:17,285 INFO Epoch 3
13: 2018-09-29 12:16:28,016 INFO   Training loss: 11.930
18: 2018-09-29 12:16:28,016 INFO   Training loss: 11.670
14: 2018-09-29 12:16:28,017 INFO   Training loss: 11.546
 8: 2018-09-29 12:16:28,016 INFO   Training loss: 11.785
31: 2018-09-29 12:16:28,017 INFO   Training loss: 11.947
27: 2018-09-29 12:16:28,016 INFO   Training loss: 12.004
29: 2018-09-29 12:16:28,017 INFO   Training loss: 11.832
20: 2018-09-29 12:16:28,016 INFO   Training loss: 11.667
11: 2018-09-29 12:16:28,017 INFO   Training loss: 11.637
10: 2018-09-29 12:16:28,017 INFO   Training loss: 11.937
17: 2018-09-29 12:16:28,016 INFO   Training loss: 11.819
21: 2018-09-29 12:16:28,016 INFO   Training loss: 11.873
28: 2018-09-29 12:16:28,015 INFO   Training loss: 11.711
23: 2018-09-29 12:16:28,017 INFO   Training loss: 11.849
 1: 2018-09-29 12:16:28,017 INFO   Training loss: 11.640
 3: 2018-09-29 12:16:28,016 INFO   Training loss: 11.967
26: 2018-09-29 12:16:28,018 INFO   Training loss: 12.028
 4: 2018-09-29 12:16:28,016 INFO   Training loss: 11.640
 5: 2018-09-29 12:16:28,017 INFO   Training loss: 11.869
 6: 2018-09-29 12:16:28,016 INFO   Training loss: 12.008
 7: 2018-09-29 12:16:28,017 INFO   Training loss: 11.846
19: 2018-09-29 12:16:28,016 INFO   Training loss: 12.065
16: 2018-09-29 12:16:28,017 INFO   Training loss: 12.001
12: 2018-09-29 12:16:28,016 INFO   Training loss: 11.623
15: 2018-09-29 12:16:28,016 INFO   Training loss: 11.886
 9: 2018-09-29 12:16:28,016 INFO   Training loss: 11.886
22: 2018-09-29 12:16:28,016 INFO   Training loss: 11.599
30: 2018-09-29 12:16:28,016 INFO   Training loss: 11.785
24: 2018-09-29 12:16:28,014 INFO   Training loss: 11.519
 2: 2018-09-29 12:16:28,016 INFO   Training loss: 11.670
25: 2018-09-29 12:16:28,017 INFO   Training loss: 11.944
 0: 2018-09-29 12:16:28,017 INFO   Training loss: 11.721
15: 2018-09-29 12:16:38,539 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:16:38,541 INFO   Validation loss: 11.783 acc: 0.574
24: 2018-09-29 12:16:38,538 INFO   Validation loss: 11.783 acc: 0.574
27: 2018-09-29 12:16:38,542 INFO   Validation loss: 11.783 acc: 0.574
 7: 2018-09-29 12:16:38,546 INFO   Validation loss: 11.783 acc: 0.574
10: 2018-09-29 12:16:38,575 INFO   Validation loss: 11.783 acc: 0.574
30: 2018-09-29 12:16:38,596 INFO   Validation loss: 11.783 acc: 0.574
 2: 2018-09-29 12:16:38,596 INFO   Validation loss: 11.783 acc: 0.574
 1: 2018-09-29 12:16:38,608 INFO   Validation loss: 11.783 acc: 0.574
 9: 2018-09-29 12:16:38,608 INFO   Validation loss: 11.783 acc: 0.574
29: 2018-09-29 12:16:38,647 INFO   Validation loss: 11.783 acc: 0.574
 8: 2018-09-29 12:16:38,651 INFO   Validation loss: 11.783 acc: 0.574
26: 2018-09-29 12:16:38,655 INFO   Validation loss: 11.783 acc: 0.574
11: 2018-09-29 12:16:38,667 INFO   Validation loss: 11.783 acc: 0.574
12: 2018-09-29 12:16:38,668 INFO   Validation loss: 11.783 acc: 0.574
 6: 2018-09-29 12:16:38,668 INFO   Validation loss: 11.783 acc: 0.574
17: 2018-09-29 12:16:38,670 INFO   Validation loss: 11.783 acc: 0.574
25: 2018-09-29 12:16:39,408 INFO Finished training
25: 2018-09-29 12:16:39,408 INFO Train samples 8192 time 17.8725s rate 458.359 samples/s
25: 2018-09-29 12:16:39,408 INFO Valid rate: 3121.07 samples/s
25: 2018-09-29 12:16:39,408 INFO All done!
 1: 2018-09-29 12:16:43,416 INFO Finished training
 1: 2018-09-29 12:16:43,416 INFO Train samples 8192 time 14.2919s rate 573.193 samples/s
 1: 2018-09-29 12:16:43,417 INFO Valid rate: 3106.36 samples/s
 1: 2018-09-29 12:16:43,417 INFO All done!
 3: 2018-09-29 12:16:43,556 INFO   Validation loss: 11.783 acc: 0.574
 4: 2018-09-29 12:16:43,597 INFO   Validation loss: 11.783 acc: 0.574
22: 2018-09-29 12:16:43,607 INFO   Validation loss: 11.783 acc: 0.574
31: 2018-09-29 12:16:43,613 INFO   Validation loss: 11.783 acc: 0.574
28: 2018-09-29 12:16:43,623 INFO   Validation loss: 11.783 acc: 0.574
16: 2018-09-29 12:16:43,655 INFO   Validation loss: 11.783 acc: 0.574
23: 2018-09-29 12:16:43,682 INFO   Validation loss: 11.783 acc: 0.574
 5: 2018-09-29 12:16:43,702 INFO   Validation loss: 11.783 acc: 0.574
 0: 2018-09-29 12:16:44,530 INFO   Validation loss: 11.783 acc: 0.574
20: 2018-09-29 12:16:44,583 INFO   Validation loss: 11.783 acc: 0.574
18: 2018-09-29 12:16:44,585 INFO   Validation loss: 11.783 acc: 0.574
21: 2018-09-29 12:16:44,588 INFO   Validation loss: 11.783 acc: 0.574
19: 2018-09-29 12:16:44,589 INFO   Validation loss: 11.783 acc: 0.574
14: 2018-09-29 12:16:44,605 INFO   Validation loss: 11.783 acc: 0.574
13: 2018-09-29 12:16:44,652 INFO   Validation loss: 11.783 acc: 0.574
15: 2018-09-29 12:16:45,171 INFO Finished training
15: 2018-09-29 12:16:45,171 INFO Train samples 8192 time 13.9085s rate 588.992 samples/s
15: 2018-09-29 12:16:45,171 INFO Valid rate: 3115.81 samples/s
15: 2018-09-29 12:16:45,171 INFO All done!
24: 2018-09-29 12:16:45,240 INFO Finished training
24: 2018-09-29 12:16:45,240 INFO Train samples 8192 time 15.812s rate 518.087 samples/s
24: 2018-09-29 12:16:45,241 INFO Valid rate: 3126.84 samples/s
24: 2018-09-29 12:16:45,241 INFO All done!
27: 2018-09-29 12:16:45,730 INFO Finished training
27: 2018-09-29 12:16:45,730 INFO Train samples 8192 time 13.8623s rate 590.954 samples/s
27: 2018-09-29 12:16:45,730 INFO Valid rate: 3110.34 samples/s
27: 2018-09-29 12:16:45,730 INFO All done!
 7: 2018-09-29 12:16:45,853 INFO Finished training
 7: 2018-09-29 12:16:45,853 INFO Train samples 8192 time 14.0512s rate 583.012 samples/s
 7: 2018-09-29 12:16:45,853 INFO Valid rate: 3115.67 samples/s
 7: 2018-09-29 12:16:45,853 INFO All done!
10: 2018-09-29 12:16:46,188 INFO Finished training
10: 2018-09-29 12:16:46,188 INFO Train samples 8192 time 14.0842s rate 581.644 samples/s
10: 2018-09-29 12:16:46,188 INFO Valid rate: 3118.31 samples/s
10: 2018-09-29 12:16:46,188 INFO All done!
30: 2018-09-29 12:16:46,211 INFO Finished training
30: 2018-09-29 12:16:46,211 INFO Train samples 8192 time 13.2481s rate 618.354 samples/s
30: 2018-09-29 12:16:46,211 INFO Valid rate: 2779.45 samples/s
30: 2018-09-29 12:16:46,211 INFO All done!
29: 2018-09-29 12:16:46,253 INFO Finished training
29: 2018-09-29 12:16:46,253 INFO Train samples 8192 time 13.8007s rate 593.592 samples/s
29: 2018-09-29 12:16:46,253 INFO Valid rate: 3100.28 samples/s
29: 2018-09-29 12:16:46,253 INFO All done!
 8: 2018-09-29 12:16:46,440 INFO Finished training
 8: 2018-09-29 12:16:46,441 INFO Train samples 8192 time 13.7312s rate 596.6 samples/s
 8: 2018-09-29 12:16:46,441 INFO Valid rate: 3093.82 samples/s
 8: 2018-09-29 12:16:46,441 INFO All done!
 2: 2018-09-29 12:16:46,526 INFO Finished training
 2: 2018-09-29 12:16:46,526 INFO Train samples 8192 time 13.8105s rate 593.172 samples/s
 2: 2018-09-29 12:16:46,526 INFO Valid rate: 3105.09 samples/s
 2: 2018-09-29 12:16:46,526 INFO All done!
 9: 2018-09-29 12:16:46,545 INFO Finished training
 9: 2018-09-29 12:16:46,545 INFO Train samples 8192 time 13.9419s rate 587.581 samples/s
 9: 2018-09-29 12:16:46,545 INFO Valid rate: 3107.44 samples/s
 9: 2018-09-29 12:16:46,545 INFO All done!
26: 2018-09-29 12:16:46,563 INFO Finished training
26: 2018-09-29 12:16:46,563 INFO Train samples 8192 time 13.7947s rate 593.852 samples/s
26: 2018-09-29 12:16:46,563 INFO Valid rate: 3095.95 samples/s
26: 2018-09-29 12:16:46,563 INFO All done!
 6: 2018-09-29 12:16:46,586 INFO Finished training
 6: 2018-09-29 12:16:46,586 INFO Train samples 8192 time 13.7897s rate 594.066 samples/s
 6: 2018-09-29 12:16:46,586 INFO Valid rate: 3094.9 samples/s
 6: 2018-09-29 12:16:46,586 INFO All done!
11: 2018-09-29 12:16:46,605 INFO Finished training
11: 2018-09-29 12:16:46,606 INFO Train samples 8192 time 11.617s rate 705.175 samples/s
11: 2018-09-29 12:16:46,606 INFO Valid rate: 2494.65 samples/s
11: 2018-09-29 12:16:46,606 INFO All done!
12: 2018-09-29 12:16:46,627 INFO Finished training
12: 2018-09-29 12:16:46,627 INFO Train samples 8192 time 16.5248s rate 495.741 samples/s
12: 2018-09-29 12:16:46,627 INFO Valid rate: 3086.74 samples/s
12: 2018-09-29 12:16:46,627 INFO All done!
17: 2018-09-29 12:16:46,645 INFO Finished training
17: 2018-09-29 12:16:46,646 INFO Train samples 8192 time 13.7283s rate 596.725 samples/s
17: 2018-09-29 12:16:46,646 INFO Valid rate: 3093.22 samples/s
17: 2018-09-29 12:16:46,646 INFO All done!
22: 2018-09-29 12:16:48,049 INFO Finished training
22: 2018-09-29 12:16:48,049 INFO Train samples 8192 time 15.1785s rate 539.71 samples/s
22: 2018-09-29 12:16:48,050 INFO Valid rate: 2295.51 samples/s
22: 2018-09-29 12:16:48,050 INFO All done!
21: 2018-09-29 12:16:48,441 INFO Finished training
21: 2018-09-29 12:16:48,441 INFO Train samples 8192 time 12.4689s rate 656.995 samples/s
21: 2018-09-29 12:16:48,441 INFO Valid rate: 1980.57 samples/s
21: 2018-09-29 12:16:48,441 INFO All done!
31: 2018-09-29 12:16:48,495 INFO Finished training
31: 2018-09-29 12:16:48,496 INFO Train samples 8192 time 12.9019s rate 634.946 samples/s
31: 2018-09-29 12:16:48,496 INFO Valid rate: 2503.46 samples/s
31: 2018-09-29 12:16:48,496 INFO All done!
23: 2018-09-29 12:16:48,563 INFO Finished training
23: 2018-09-29 12:16:48,563 INFO Train samples 8192 time 12.8578s rate 637.123 samples/s
23: 2018-09-29 12:16:48,563 INFO Valid rate: 2282.44 samples/s
23: 2018-09-29 12:16:48,563 INFO All done!
 4: 2018-09-29 12:16:49,228 INFO Finished training
 4: 2018-09-29 12:16:49,228 INFO Train samples 8192 time 12.3888s rate 661.24 samples/s
 4: 2018-09-29 12:16:49,229 INFO Valid rate: 2290.36 samples/s
 4: 2018-09-29 12:16:49,229 INFO All done!
 3: 2018-09-29 12:16:49,911 INFO Finished training
 3: 2018-09-29 12:16:49,911 INFO Train samples 8192 time 11.2243s rate 729.846 samples/s
 3: 2018-09-29 12:16:49,912 INFO Valid rate: 2103.41 samples/s
 3: 2018-09-29 12:16:49,912 INFO All done!
28: 2018-09-29 12:16:49,935 INFO Finished training
28: 2018-09-29 12:16:49,935 INFO Train samples 8192 time 11.2497s rate 728.195 samples/s
28: 2018-09-29 12:16:49,935 INFO Valid rate: 2101.3 samples/s
28: 2018-09-29 12:16:49,935 INFO All done!
16: 2018-09-29 12:16:49,997 INFO Finished training
16: 2018-09-29 12:16:49,997 INFO Train samples 8192 time 11.1332s rate 735.814 samples/s
16: 2018-09-29 12:16:49,998 INFO Valid rate: 2097.46 samples/s
16: 2018-09-29 12:16:49,998 INFO All done!
 5: 2018-09-29 12:16:50,100 INFO Finished training
 5: 2018-09-29 12:16:50,101 INFO Train samples 8192 time 14.0341s rate 583.719 samples/s
 5: 2018-09-29 12:16:50,101 INFO Valid rate: 2777.93 samples/s
 5: 2018-09-29 12:16:50,101 INFO All done!
 0: 2018-09-29 12:16:50,250 INFO Saving summaries to /global/cscratch1/sd/sfarrell/hep-cnn-pytorch/summaries.npz
 0: 2018-09-29 12:16:50,269 INFO Finished training
 0: 2018-09-29 12:16:50,269 INFO Train samples 8192 time 11.8397s rate 691.911 samples/s
 0: 2018-09-29 12:16:50,269 INFO Valid rate: 2212.87 samples/s
 0: 2018-09-29 12:16:50,269 INFO All done!
20: 2018-09-29 12:16:50,271 INFO Finished training
20: 2018-09-29 12:16:50,271 INFO Train samples 8192 time 11.012s rate 743.919 samples/s
20: 2018-09-29 12:16:50,271 INFO Valid rate: 2012.08 samples/s
20: 2018-09-29 12:16:50,272 INFO All done!
19: 2018-09-29 12:16:50,287 INFO Finished training
19: 2018-09-29 12:16:50,288 INFO Train samples 8192 time 11.4541s rate 715.204 samples/s
19: 2018-09-29 12:16:50,288 INFO Valid rate: 1981.06 samples/s
19: 2018-09-29 12:16:50,288 INFO All done!
18: 2018-09-29 12:16:50,314 INFO Finished training
18: 2018-09-29 12:16:50,315 INFO Train samples 8192 time 11.0237s rate 743.125 samples/s
18: 2018-09-29 12:16:50,315 INFO Valid rate: 2012.65 samples/s
18: 2018-09-29 12:16:50,315 INFO All done!
14: 2018-09-29 12:16:50,341 INFO Finished training
14: 2018-09-29 12:16:50,341 INFO Train samples 8192 time 10.9254s rate 749.815 samples/s
14: 2018-09-29 12:16:50,341 INFO Valid rate: 1972.05 samples/s
14: 2018-09-29 12:16:50,342 INFO All done!
13: 2018-09-29 12:16:50,366 INFO Finished training
13: 2018-09-29 12:16:50,366 INFO Train samples 8192 time 10.8846s rate 752.622 samples/s
13: 2018-09-29 12:16:50,366 INFO Valid rate: 1976.09 samples/s
13: 2018-09-29 12:16:50,366 INFO All done!
